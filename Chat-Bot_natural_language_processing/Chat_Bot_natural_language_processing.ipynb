{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT4gKO10yQHkuh0Xem5IFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozj1/Machine_Learning_and_Data_Science_projects/blob/main/Chat-Bot_natural_language_processing/Chat_Bot_natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data\n",
        "\n",
        "We will be working with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ],
      "metadata": {
        "id": "J-JpZRKJ-Ae-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTkh-4-XRBet",
        "outputId": "1e634924-8e57-4a14-9524-eeb51069c5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0GRWATf2A7Z-",
        "outputId": "4e11bfc7-e740-4abe-dc43-742c6c83e0e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "W-7nlyz69oul"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "V1Mr5f2I9oun"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "sNplFO3P9ouo"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## understanding the dataset format, a short story, a question, and an answer Yes or No"
      ],
      "metadata": {
        "id": "CtJXt0elDjxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_data))\n",
        "print(type(train_data))\n",
        "print(len(test_data))\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBV7H4PED5aa",
        "outputId": "0a6634dc-f254-46f4-fffc-5f8b21c43d3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "1000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehi_BpS6EKmT",
        "outputId": "f91f1d5f-f5b0-4495-f620-83c67b94e7d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping to get the sentence\n",
        "print(' '.join(train_data[0][0]))\n",
        "print(' '.join(train_data[0][1]))\n",
        "#now what is the answer?\n",
        "print(train_data[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3awpdMHqENdr",
        "outputId": "2f69e6a8-9d59-46e9-e222-aaa7056a12f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
            "Is Sandra in the hallway ?\n",
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how many unique words we have in the entire dataset using set() and unite them using union()."
      ],
      "metadata": {
        "id": "raARcfFcE_nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()\n",
        "all_data = test_data + train_data\n",
        "\n",
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "\n",
        "#answer dataset only has two words, we add them\n",
        "vocab.add('no')\n",
        "vocab.add('yes')\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0bP9JaFP3B",
        "outputId": "7479e83a-d724-41ac-84f6-36e22cbad532"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences\n",
        "#we find the max size of a story\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "print(max_story_len)\n",
        "#we find the max size of a question in the dataset\n",
        "max_question_len = max([len(data[1]) for data in all_data])\n",
        "print(max_question_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtXL9fwgFlHJ",
        "outputId": "6aed9410-88e7-4002-8e5b-3421052aca3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We vectorize the data so it can be understood by Keras."
      ],
      "metadata": {
        "id": "NKztrBDXG7_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eTQ3PnHJRp",
        "outputId": "204dfb22-3adf-4886-8dc6-192c880ae0dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'milk': 1,\n",
              " 'john': 2,\n",
              " 'no': 3,\n",
              " 'is': 4,\n",
              " '?': 5,\n",
              " 'kitchen': 6,\n",
              " 'grabbed': 7,\n",
              " 'back': 8,\n",
              " 'daniel': 9,\n",
              " 'took': 10,\n",
              " 'picked': 11,\n",
              " 'to': 12,\n",
              " 'bathroom': 13,\n",
              " '.': 14,\n",
              " 'travelled': 15,\n",
              " 'sandra': 16,\n",
              " 'in': 17,\n",
              " 'went': 18,\n",
              " 'put': 19,\n",
              " 'moved': 20,\n",
              " 'yes': 21,\n",
              " 'garden': 22,\n",
              " 'dropped': 23,\n",
              " 'office': 24,\n",
              " 'mary': 25,\n",
              " 'football': 26,\n",
              " 'apple': 27,\n",
              " 'journeyed': 28,\n",
              " 'down': 29,\n",
              " 'there': 30,\n",
              " 'the': 31,\n",
              " 'bedroom': 32,\n",
              " 'discarded': 33,\n",
              " 'hallway': 34,\n",
              " 'got': 35,\n",
              " 'left': 36,\n",
              " 'up': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "# We make separate lists for story, query, and answer.\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "B39NQvOxHuDy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
        "\n",
        "print(len(train_story_text))\n",
        "print(len(train_story_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezWjYjFpH2gY",
        "outputId": "17350d29-9f9c-4a9d-d799-dd322ac9d389"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functionalize Vectorization"
      ],
      "metadata": {
        "id": "bScJEEHeIbnC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "T5grEdyr9ou9"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "pCRYzkAr9ou-"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "iFPb4OhM9ou_"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p8xQt2UB9ou_",
        "outputId": "d3e42a02-3080-4455-d69e-7d94ace52cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 31, 32, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 31, 27, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 27, 30, 14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6mH0IsXV9ovA",
        "outputId": "7501442a-6368-4019-cf63-880c5b82a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31, 22,  5],\n",
              "       ...,\n",
              "       [ 4, 25, 17, 31, 32,  5],\n",
              "       [ 4, 16, 17, 31, 22,  5],\n",
              "       [ 4, 25, 17, 31, 22,  5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DhaDoUld9ovB",
        "outputId": "5ec10f9c-9eb8-4490-9bf3-a7e94425ecc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "idSgpnbN9ovB",
        "outputId": "887a36f9-e03c-42b1-95ce-fbead1422742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Gi2_q80D9ovC",
        "outputId": "b92ecb97-f4bc-4eee-893f-41b326a7f9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vXD3zd239ovD",
        "outputId": "de8df310-ae09-49de-8c92-129d4c7ed50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0RJITpT9ovD"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "id": "R0KQrG9t9ovE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWlJY0gQ9ovE"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "id": "2ChjupFZ9ovE"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvItdiz49ovF"
      },
      "source": [
        "## Encoders\n",
        "we build the model as described in the paper \n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "GwDB3MqU9ovG"
      },
      "outputs": [],
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV8TLTkI9ovG"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": true,
        "id": "E9Sx1YK39ovG"
      },
      "outputs": [],
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4evnPaZe9ovH"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "id": "ZcxXzVi-9ovH"
      },
      "outputs": [],
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58J0Cg5R9ovI"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "B4FWaclS9ovI"
      },
      "outputs": [],
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esvE3bZp9ovJ"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "id": "EIDwu68U9ovJ"
      },
      "outputs": [],
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNQ-sD2H9ovK"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": true,
        "id": "d7MQWcZC9ovK"
      },
      "outputs": [],
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMlPMPgg9ovL"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "id": "aYp-et4a9ovL"
      },
      "outputs": [],
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "F-eq5Knj9ovL",
        "outputId": "cdc78ea6-c392-4409-96c5-20931ceac0d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": true,
        "id": "_TK1sR899ovM"
      },
      "outputs": [],
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "id": "TK4INMhM9ovM"
      },
      "outputs": [],
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "id": "LblmnAPw9ovN"
      },
      "outputs": [],
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "eMXwsjPk9ovN",
        "outputId": "8d9af498-fc8e-4f05-ab34-a22efa3f091b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 64)     2432        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 6, 64)        2432        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, None, 6)      228         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "8Cy5L0Fk9ovO",
        "outputId": "9c6e7f7a-52b1-4ef0-da1a-0d618b72758c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 8s 16ms/step - loss: 0.9453 - accuracy: 0.4941 - val_loss: 0.6979 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.7096 - accuracy: 0.4989 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6988 - accuracy: 0.5018 - val_loss: 0.7006 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6963 - accuracy: 0.4944 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6957 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6955 - accuracy: 0.4976 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6955 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6955 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6950 - accuracy: 0.5101 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6949 - accuracy: 0.5018 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6952 - accuracy: 0.5014 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6955 - accuracy: 0.4952 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6943 - accuracy: 0.5107 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6949 - accuracy: 0.5018 - val_loss: 0.6961 - val_accuracy: 0.4970\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6954 - accuracy: 0.4979 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6953 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6952 - accuracy: 0.4988 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6950 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6945 - accuracy: 0.5107 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6956 - accuracy: 0.4957 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.4982 - val_loss: 0.6969 - val_accuracy: 0.4970\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6953 - accuracy: 0.4960 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6956 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6954 - accuracy: 0.4918 - val_loss: 0.6964 - val_accuracy: 0.5030\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6953 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.5040 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6946 - accuracy: 0.4992 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6946 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6954 - accuracy: 0.4961 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.6952 - accuracy: 0.4923 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6950 - accuracy: 0.4997 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6946 - accuracy: 0.5099 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6948 - accuracy: 0.5045 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6950 - accuracy: 0.4951 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6949 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6955 - accuracy: 0.4922 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6951 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6956 - accuracy: 0.4892 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6952 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6943 - accuracy: 0.5063 - val_loss: 0.6955 - val_accuracy: 0.5030\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6946 - accuracy: 0.5077 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6952 - accuracy: 0.5022 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6944 - accuracy: 0.5029 - val_loss: 0.6961 - val_accuracy: 0.4970\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6946 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6942 - accuracy: 0.5040 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.5073 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6943 - accuracy: 0.5074 - val_loss: 0.6940 - val_accuracy: 0.4950\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6940 - accuracy: 0.5121 - val_loss: 0.6944 - val_accuracy: 0.4820\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6944 - val_accuracy: 0.5050\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6938 - val_accuracy: 0.5050\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5230\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6885 - accuracy: 0.5254 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6825 - accuracy: 0.5479 - val_loss: 0.6836 - val_accuracy: 0.5350\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6725 - accuracy: 0.5823 - val_loss: 0.6543 - val_accuracy: 0.6270\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6530 - accuracy: 0.6242 - val_loss: 0.6323 - val_accuracy: 0.6380\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6446 - accuracy: 0.6403 - val_loss: 0.6293 - val_accuracy: 0.6700\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6354 - accuracy: 0.6454 - val_loss: 0.6200 - val_accuracy: 0.6620\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6286 - accuracy: 0.6554 - val_loss: 0.6106 - val_accuracy: 0.6750\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6233 - accuracy: 0.6615 - val_loss: 0.6031 - val_accuracy: 0.6850\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6124 - accuracy: 0.6706 - val_loss: 0.6021 - val_accuracy: 0.6890\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6047 - accuracy: 0.6787 - val_loss: 0.5924 - val_accuracy: 0.6810\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5949 - accuracy: 0.6913 - val_loss: 0.5651 - val_accuracy: 0.7060\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.5750 - accuracy: 0.7141 - val_loss: 0.5650 - val_accuracy: 0.7090\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5556 - accuracy: 0.7324 - val_loss: 0.5150 - val_accuracy: 0.7650\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5235 - accuracy: 0.7551 - val_loss: 0.5105 - val_accuracy: 0.7790\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4984 - accuracy: 0.7687 - val_loss: 0.4859 - val_accuracy: 0.7900\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4727 - accuracy: 0.7900 - val_loss: 0.4390 - val_accuracy: 0.8030\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4506 - accuracy: 0.7990 - val_loss: 0.4206 - val_accuracy: 0.8130\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4305 - accuracy: 0.8144 - val_loss: 0.4089 - val_accuracy: 0.8210\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4142 - accuracy: 0.8222 - val_loss: 0.3929 - val_accuracy: 0.8150\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4121 - accuracy: 0.8253 - val_loss: 0.3839 - val_accuracy: 0.8230\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3996 - accuracy: 0.8341 - val_loss: 0.4053 - val_accuracy: 0.8000\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3926 - accuracy: 0.8292 - val_loss: 0.3993 - val_accuracy: 0.8220\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.3777 - val_accuracy: 0.8260\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3819 - accuracy: 0.8376 - val_loss: 0.3747 - val_accuracy: 0.8280\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3731 - accuracy: 0.8382 - val_loss: 0.3783 - val_accuracy: 0.8290\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3677 - accuracy: 0.8431 - val_loss: 0.3680 - val_accuracy: 0.8350\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3679 - accuracy: 0.8419 - val_loss: 0.3763 - val_accuracy: 0.8270\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3599 - accuracy: 0.8470 - val_loss: 0.4567 - val_accuracy: 0.8080\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 6s 21ms/step - loss: 0.3538 - accuracy: 0.8483 - val_loss: 0.3713 - val_accuracy: 0.8310\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3547 - accuracy: 0.8488 - val_loss: 0.3937 - val_accuracy: 0.8200\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3532 - accuracy: 0.8494 - val_loss: 0.3760 - val_accuracy: 0.8290\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3502 - accuracy: 0.8493 - val_loss: 0.3554 - val_accuracy: 0.8390\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3490 - accuracy: 0.8490 - val_loss: 0.3663 - val_accuracy: 0.8240\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3431 - accuracy: 0.8498 - val_loss: 0.3669 - val_accuracy: 0.8370\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3415 - accuracy: 0.8525 - val_loss: 0.3800 - val_accuracy: 0.8120\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3406 - accuracy: 0.8548 - val_loss: 0.3501 - val_accuracy: 0.8330\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3346 - accuracy: 0.8550 - val_loss: 0.3872 - val_accuracy: 0.8190\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3336 - accuracy: 0.8551 - val_loss: 0.3563 - val_accuracy: 0.8360\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3332 - accuracy: 0.8589 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3279 - accuracy: 0.8591 - val_loss: 0.3413 - val_accuracy: 0.8370\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3318 - accuracy: 0.8571 - val_loss: 0.3812 - val_accuracy: 0.8180\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3211 - accuracy: 0.8581 - val_loss: 0.3492 - val_accuracy: 0.8310\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3298 - accuracy: 0.8572 - val_loss: 0.3498 - val_accuracy: 0.8400\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3226 - accuracy: 0.8595 - val_loss: 0.3780 - val_accuracy: 0.8280\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3269 - accuracy: 0.8572 - val_loss: 0.3922 - val_accuracy: 0.8210\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3245 - accuracy: 0.8618 - val_loss: 0.4012 - val_accuracy: 0.8130\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3252 - accuracy: 0.8600 - val_loss: 0.3693 - val_accuracy: 0.8250\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3198 - accuracy: 0.8639 - val_loss: 0.3626 - val_accuracy: 0.8320\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3182 - accuracy: 0.8617 - val_loss: 0.3686 - val_accuracy: 0.8370\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3148 - accuracy: 0.8634 - val_loss: 0.3597 - val_accuracy: 0.8320\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3172 - accuracy: 0.8630 - val_loss: 0.3498 - val_accuracy: 0.8290\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3159 - accuracy: 0.8623 - val_loss: 0.4080 - val_accuracy: 0.8160\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3171 - accuracy: 0.8636 - val_loss: 0.3675 - val_accuracy: 0.8260\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3103 - accuracy: 0.8679 - val_loss: 0.3992 - val_accuracy: 0.8230\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3126 - accuracy: 0.8649 - val_loss: 0.3766 - val_accuracy: 0.8280\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3113 - accuracy: 0.8658 - val_loss: 0.4021 - val_accuracy: 0.8160\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3108 - accuracy: 0.8632 - val_loss: 0.3742 - val_accuracy: 0.8280\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3049 - accuracy: 0.8690 - val_loss: 0.3666 - val_accuracy: 0.8250\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3068 - accuracy: 0.8664 - val_loss: 0.3776 - val_accuracy: 0.8250\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3077 - accuracy: 0.8677 - val_loss: 0.3780 - val_accuracy: 0.8250\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3059 - accuracy: 0.8701 - val_loss: 0.3715 - val_accuracy: 0.8230\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3034 - accuracy: 0.8691 - val_loss: 0.4189 - val_accuracy: 0.8250\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3007 - accuracy: 0.8675 - val_loss: 0.3982 - val_accuracy: 0.8230\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3005 - accuracy: 0.8721 - val_loss: 0.3609 - val_accuracy: 0.8240\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3013 - accuracy: 0.8700 - val_loss: 0.3767 - val_accuracy: 0.8220\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3041 - accuracy: 0.8669 - val_loss: 0.4152 - val_accuracy: 0.8110\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.3000 - accuracy: 0.8697 - val_loss: 0.3860 - val_accuracy: 0.8220\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3047 - accuracy: 0.8666 - val_loss: 0.3706 - val_accuracy: 0.8260\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3002 - accuracy: 0.8681 - val_loss: 0.4153 - val_accuracy: 0.8210\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFKFXuDt9ovO"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": true,
        "id": "AK2cICPA9ovP"
      },
      "outputs": [],
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "model.save(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDJrQIcA9ovP"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Plotting Out Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "by9759CY9ovP",
        "outputId": "39027e54-7307-4129-f744-0930edde3e90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABGyElEQVR4nO3dd3xV9fnA8c+THRIIkMFICIQ9BBkBwYmD4UKtVnFrrVit1tZRtVWrVlvbn3XVPahbtBQVFQVEQJEZhuwRdsIKCYGE7OT5/fE9yCUkcEHCzXjer1deuWfd85xcOM/9jvP9iqpijDHGVBYU6ACMMcbUTpYgjDHGVMkShDHGmCpZgjDGGFMlSxDGGGOqZAnCGGNMlSxBGAOIyFsi8rif+24QkXNqOiZjAs0ShDHGmCpZgjCmHhGRkEDHYOoPSxCmzvCqdu4VkcUisldE3hSRFiLylYjkicg3ItLMZ/8RIrJMRHJFZJqIdPPZ1kdEFnjHfQREVDrXBSKyyDt2poj08jPG80VkoYjsEZHNIvJIpe2neu+X622/wVsfKSL/EpGNIrJbRGZ46waLSEYVf4dzvNePiMhYEXlPRPYAN4jIABGZ5Z1jq4i8ICJhPsf3EJHJIpIjIttF5E8i0lJECkQk1me/viKSJSKh/ly7qX8sQZi65lJgCNAZuBD4CvgTEI/79/w7ABHpDHwI/N7bNgH4XETCvJvlp8C7QHPgv9774h3bBxgN3ALEAq8C40Uk3I/49gLXAU2B84FbReRi733bevH+24upN7DIO+4poB9wshfTH4EKP/8mFwFjvXO+D5QDfwDigEHA2cBtXgyNgW+Ar4HWQEdgiqpuA6YBl/u877XAGFUt9TMOU89YgjB1zb9VdbuqZgLfA3NUdaGqFgGfAH28/a4AvlTVyd4N7ikgEncDHgiEAs+qaqmqjgXm+ZxjFPCqqs5R1XJVfRso9o47JFWdpqpLVLVCVRfjktQZ3uargG9U9UPvvNmqukhEgoBfAXeqaqZ3zpmqWuzn32SWqn7qnbNQVeer6mxVLVPVDbgEty+GC4BtqvovVS1S1TxVneNtexu4BkBEgoErcUnUNFCWIExds93ndWEVy9He69bAxn0bVLUC2Awketsy9cCRKjf6vG4L3O1V0eSKSC7QxjvukETkJBGZ6lXN7AZ+g/smj/cea6s4LA5XxVXVNn9srhRDZxH5QkS2edVOf/MjBoDPgO4ikoIrpe1W1blHGZOpByxBmPpqC+5GD4CICO7mmAlsBRK9dfsk+7zeDDyhqk19fhqp6od+nPcDYDzQRlVjgFeAfefZDHSo4pidQFE12/YCjXyuIxhXPeWr8pDMLwMrgU6q2gRXBecbQ/uqAvdKYR/jShHXYqWHBs8ShKmvPgbOF5GzvUbWu3HVRDOBWUAZ8DsRCRWRXwADfI59HfiNVxoQEYnyGp8b+3HexkCOqhaJyABctdI+7wPniMjlIhIiIrEi0tsr3YwGnhaR1iISLCKDvDaP1UCEd/5Q4EHgcG0hjYE9QL6IdAVu9dn2BdBKRH4vIuEi0lhETvLZ/g5wAzACSxANniUIUy+p6ircN+F/476hXwhcqKolqloC/AJ3I8zBtVeM8zk2DbgZeAHYBaR7+/rjNuAxEckDHsYlqn3vuwk4D5escnAN1Cd6m+8BluDaQnKAfwBBqrrbe883cKWfvcABvZqqcA8uMeXhkt1HPjHk4aqPLgS2AWuAM322/4BrHF+gqr7VbqYBEpswyBjjS0S+BT5Q1TcCHYsJLEsQxpifiEh/YDKuDSUv0PGYwLIqJmMMACLyNu4Zid9bcjBgJQhjjDHVsBKEMcaYKtWbgb3i4uK0Xbt2gQ7DGGPqlPnz5+9U1crP1gD1KEG0a9eOtLS0QIdhjDF1iohU253ZqpiMMcZUyRKEMcaYKlmCMMYYU6V60wZRldLSUjIyMigqKgp0KDUuIiKCpKQkQkNtbhdjzLFRrxNERkYGjRs3pl27dhw4cGf9oqpkZ2eTkZFBSkpKoMMxxtQT9bqKqaioiNjY2HqdHABEhNjY2AZRUjLGHD/1OkEA9T457NNQrtMYc/zU+wRhjDF1RfqOfN6ZtYGcvSWBDgWwBFHjcnNzeemll474uPPOO4/c3NxjH5AxJmB27Cli9Iz1TFiylc05BfiOhTd/Yw6XvjyThz9bxsC/T+GujxaxZvuBYyZm7CpgZ76/U5X/fPW6kbo22JcgbrvttgPWl5WVERJS/Z9/woQJNR2aMcZPqsp3a3bSMzGG5lFh1e5XUFLGLe/OJzhI+MM5nTmxTVNUlZXb8nh39kbGpmVQUl7x0/4JjcMZ0r0FnRKiefLrlbRsEsELV/Vh8vLtjFuQyfgft/Dr09pzRf82vDwtnf/OzyAyNJg/nNOZG05pR35RGdNXZ1FSXsHlqW2O+XXXm9FcU1NTtfJQGytWrKBbt24BisgZOXIkn332GV26dCE0NJSIiAiaNWvGypUrWb16NRdffDGbN2+mqKiIO++8k1GjRgH7hw7Jz8/n3HPP5dRTT2XmzJkkJiby2WefERkZedC5asP1GlPflJRV8MC4JfxvQQYxkaHcM6wLVw1IJju/mPQd+XRp2ZjY6HDKK5Rb3p3PlJXbiYkMJbeglH5tm7Exey8780sICw7i0n5J3HRqO/YWl7Mkczcz1+5k2qosCkrK6ZkYw39u7E9ctJtRNju/mL9/tZKx890EgmHBQVw7qC0bdu5lysodxDcOJzu/mAqFXkkxjL/91KO6PhGZr6qpVW5rKAni0c+XsXzLnmN6zu6tm/CXC3sccp8NGzZwwQUXsHTpUqZNm8b555/P0qVLf+qOmpOTQ/PmzSksLKR///5Mnz6d2NjYAxJEx44dSUtLo3fv3lx++eWMGDGCa6655qBzWYIwpnp5RaWs2JpHn+SmhAbvr13fXVBKo/DgA9btsyOviDs+WMic9TncfFoKy7bsYebabCJCgygqdSWBRmHBXH9yO/YUlvL+nE08cmF3Lkttw1s/rOeLxVvp1qoJgzrEMrhLPAmNIw46R1FpOcu27KF7qyZEhgUftH3OumxmpO/kl/3akBzbCFVl0vLtfDRvMye0bsJZ3VrQKzGGoKCj66hyqARhVUzH2YABAw54VuH555/nk08+AWDz5s2sWbOG2NjYA45JSUmhd+/eAPTr148NGzYcr3CNqZMKSsrYnFNI5xbRiAjLt+zh1vfnszG7gJZNIrh2UFvKK5QvFm9h9fZ8ABpHhNCiSQTtYhsRFx3Ojxm7WbF1D2HBQTx7RW8u7pOIqvLV0m3MWptNh/go2sZG8cnCTF6ZvhZVuOnUFG44xf3/vv2sTtx+VqfDxhoRGky/ts2q3X5S+1hOar//niAiDOvRkmE9Wv7Mv9LhNZgEcbhv+sdLVFTUT6+nTZvGN998w6xZs2jUqBGDBw+u8lmG8PDwn14HBwdTWFh4XGI1pi4oK6+gXJXwEPftOzO3kOvenMParL0kNYvk9M7x/G9+Bk0bhfL4xScwcdk2/m/iKkSgf7vm/HF4F8rKlZy9JWzJLWRTTgFpG3fRvVUT7hnamWE9WtKpRWPA3ZzP69mK83q2+un8Z3ZN4LYzO7BwU26NtAMEUoNJEIHSuHFj8vKqnr1x9+7dNGvWjEaNGrFy5Upmz559nKMzpvZQVT6Yu4l3Z21kb0kZhSUVdGvVmCsHJHN2twS27S5iaaarJu7aqjHNGoXx4dxN/OeHDRSWlDFyQDJndkng3rE/kl9cxp/O68qM9GzGzN3EwPaxPH9lH+Kiw7lmYFs2Zu8lIjSYFk0OrvI5Gl1bNqFryybH5L1qE0sQNSw2NpZTTjmFE044gcjISFq0aPHTtuHDh/PKK6/QrVs3unTpwsCBAwMYqTGBk19cxgPjlvD5j1s4sU1TurdqQkiwMGPNTm57fwHBQUJ5RdXtpad3jqdZo1DemrmBN2esJ75xOB/fMohurZow6vQOFJWWExF6YN1+29ioKt/LHKhGG6lFZDjwHBAMvKGqT1bangy8DTT19rlfVSeISDtgBbDK23W2qv7mUOeqrb2YjqeGdr2mbqmoUKas3MFH8zaTvbeYwpJyissqKC2vYHdhKXuLy7h7aBduPaPDTw2u5RXKd6uzmLl2J+3jozmhdQwisHJbHpm7ChnaowXdWrlv7pm5hYxftIULerWiTfNGgbzUOiUgjdQiEgy8CAwBMoB5IjJeVZf77PYg8LGqviwi3YEJQDtv21pV7V1T8Rljjo/yCuWThZm8PC2dtVl7aRUTQceEaOKiwwkPCSIsOIiwENcFtH+75gccGxwknNk1gTO7Jhyw/oTEmIPOk9g0klsHd6jRa2loarKKaQCQrqrrAERkDHAR4JsgFNhXcRcDbKnBeIwxx9i+GoiqxgLbU1TKzPRsnp68itXb8+neqgnPjezN+T1bEVJFl1JT+9RkgkgENvssZwAnVdrnEWCSiNwBRAHn+GxLEZGFwB7gQVX9vvIJRGQUMAogOTn52EVujPmJqrI2K58563PI2FXI9j1FbN9TROauQrbsLqKkrILQYCEsOIjGEaE0jghhd2EpO/LckBDt46J46eq+nHtCSxtUso4JdCP1lcBbqvovERkEvCsiJwBbgWRVzRaRfsCnItJDVQ940k1VXwNeA9cGcbyDN6a+e2/2Rp6bsoYs72YfGizER4eT0CSCHokxDO3RkoiQIEorlOLSCvKLS9lTWEZUeAgdE6Lp0jKa0zrFV/kQmqn9ajJBZAK+nYKTvHW+bgKGA6jqLBGJAOJUdQdQ7K2fLyJrgc5AGsaY4+I/P6zn0c+Xc1JKc+4e0plBHWJp06zRUT+xa+qemkwQ84BOIpKCSwwjgasq7bMJOBt4S0S6ARFAlojEAzmqWi4i7YFOwLoajNWYBq2iQnn+2zUs2JRLv+RmVKjy3JQ1DOvRgheu6mslgAaqxj51VS0Dbgcm4rqsfqyqy0TkMREZ4e12N3CziPwIfAjcoK7V63RgsYgsAsYCv1HVnJqKtSYd7XDfAM8++ywFBQXHOCJjDlRRofz50yU8+80aNuzcy7NTVvPclDUM6d6Cf19Zi5ND9lqoJ2PJ1VYNZrC+QPEdrO9I7RuwLy4uzq/9a8P1mrqhokLZmV9MRm4h787ayCcLM7n9zI7cPbQze4rKWL9zLz1aN/E/OexMh+//Bec/BWFH+RBaRQUseh82zICu50OXcyE4tOp9V3wOH10Dv3wbelx8dOczgA3WF1D3338/a9eupXfv3gwZMoSEhAQ+/vhjiouLueSSS3j00UfZu3cvl19+ORkZGZSXl/PQQw+xfft2tmzZwplnnklcXBxTp04N9KWYekBVmbhsG3+bsJJNOftLp3cN6czvznYDy8VEhtK7TdMje+PJD8GqCdDhLOj1S7dubzZ88zAM+Ss0an7o47cshC/vhsz5EBoFi8dAVAJc9CJ0HnrgvmXFMOkh93rOK0eeIMrLYOoTENcZel95ZMc2MA0nQXx1P2xbcmzfs2VPOPfJQ+7y5JNPsnTpUhYtWsSkSZMYO3Ysc+fORVUZMWIE3333HVlZWbRu3Zovv/wScGM0xcTE8PTTTzN16lS/SxDG7FNWXsG2PUUkNdv/RPGW3ELu/vhHZq3LpnOLaB4d0YM2zSNpFxtF+/hoWPg+lOyFk0Yd2cm2LHTJAWDZJ/sTxPzRsPA9SD4Z+lxd/fFFe+A/57uSxyWvwgmXQfo3MOFemPH0wQli7uuwaz10Hg6rv3b/r1v29C/W8jL4ZBQs/Z9bLt4DJ91yZNfbgNTSysX6adKkSUyaNIk+ffrQt29fVq5cyZo1a+jZsyeTJ0/mvvvu4/vvvycm5uCnRI05Eg99tozT/zmVTxa6yWay84u55o05LMnczV8v6sGE353G9Se346yuLVxyWP4ZfHYbfHUvbJx1ZCeb9iRENIXe10D6ZHfDr6hwyQFg66L9+5aVwIQ/Qs76/evWfgule+GXb8GJIyE4BLoMh56XQsY8KM7fv29BDnz3T+h4DlzyCoREuoThj/IyGPdrlxzOegi6XgBf/RFmv3xk19uANJwSxGG+6R8PqsoDDzzALbcc/I1lwYIFTJgwgQcffJCzzz6bhx9+OAARmvpgaeZuxszbROPwEO76+Ed2F5QybmEmmbmFvHvTSQxIqVTdk7kAxt0CSf0hbzt8fif85nsI2T/MPKrw7V+h+8XQqpfPsfPdt/izHoSUM2DRe7DqK2jSCnZtgOAwV8LYZ/NsmPsqVJTBBU+7dasnugTTptJztO0Hw4xnYOPM/aWI6f+E4jwY+jhENnOllcUfw5BH3fKhTHrQlXCGPg4n3+GS1dgb4ev7XbvHsL9Bs7b+/6EbACtB1DDf4b6HDRvG6NGjyc9334gyMzPZsWMHW7ZsoVGjRlxzzTXce++9LFiw4KBjjfGHqvLYF8tp1iiMb+46g1M7xvHI58tZtmUPL13dd39yKNwFqye5G+6HV0JUHIz8AM7/F+xcBT88d+Ab56xzjdAT/3Tg+mlPuhvzgFsgMRWaJLmb8IJ3IDwG+lzrqoDKy9z++0ony8a5G3RFOayZBJ2GuJKDrzYDISQC1k1zy8V57n17XQEJXmeM/jdDWaGrHjuU1ZNgzssuzpPvcOtCwlyp5eyHXSnmxQH7Sz2H/iMfWKrZt65w1+GPrWMsQdQw3+G+J0+ezFVXXcWgQYPo2bMnl112GXl5eSxZsoQBAwbQu3dvHn30UR588EEARo0axfDhwznzzDMDfBWmrvhq6Tbmrs/hriGdSWgSwevXpXLjKe144co+nN01AdZ/B2N/BU91hg9+6RprGzWHqz6C6AT3Tb3HL+C7/3PdSPfJ8HoIbvjelRoA1k13N/dT7oSIJhAU5BqM106B5ePdt/vkQVBWBFkr3TEbf4DgcHczTf/GlV4Kdrr2hMpCIyB54P4EsXScq4rqd+P+fVr1cueY9YKrfqpK3nb49FZocQIMeezAbcGhcNrd8Nu50OpEmPhnKPWZtKusBEp8upqXFsJ7l8JzJ7qqtH3S3oR/pMDnv68+jmOtaHeNn8K6udYjDe16zYGWZOzmlnfTaBIZyhd3nHrggHjF+TD+dvftPiIGeo2E7iOgZS93c/e1Zys83Q0GPwCD73PrvrwHFn0AQSHQ4Uy4bDS8dgYU7obb57mbObhE8sbZ7vWo6RAWDS/0gxEvuPaFJ5Pd7+Xjod0pENvJVSPdm151T6cZz8A3j8Ddq+Gjq91N+bdzwHdMp8wF8OYQ6HIeXP7OgdtU4f3LXBXSqOmQ0LX6P+DaqfDuxXDpm9DzMrfuvzfAmm9g8P3Q9zr4+Nr9Ceu8p2DAza695YV+roRTkOP+nh3PASo9cR7bAXpfBU2TYe9O+HEMFOa4zyK+s9unrNglocim1cdZVuKqxdLedNVig35b/b5+sG6uxtRjeUWl/GvSat6btY67I7/gjAtGHZgcste6ZwayVrrG2UG/hdDI6t+wSSv3bXrdtP0JImMeJPWD1n1h5vMw7e+u6ujSN/cnB4DEftC0rUtCrXu7m2dYY9dQndANSgsg5XQICoX5b0HMUldKqK4bbPvB7vfc11wMQx8/MAEAJPZ11/XNX1wVVL/r92/LSHMllaGPHzo5gGtDaZrs3qPnZbD1R5dQY5Jh0p9daau0EC5+Gea94RrH+//aVU/lrHN/i4TuLo6MtEpvrrDkv65KLrEvbF0MFaUgwa7qLqm/Sw47VoCWQ6dh0O8GV/UW5DPZ0Z6t8PF1kDEX4ru5Kj+t2F9tdoxZgjCmLiothFkvoL1Gctv/tjAjfScvdJjP+RljIDMWevZz+6nCOxdDSR5c8z/3nII/2g921TbF+SBBsH2pq0rqfzPMfslVQSWmwgmXHnicCFwzbv8DbkFBLlFsWehuvuC6vTZNdo3VOWsPvKFX1rKXa+OY8YxLKr1GVr3fyb9zN+qv74e2J0Oce6aDua+5BNXvhsNfc1CQazOZ+oTrZTXtSZfofvM9bJoF3z3lusT2uhwQ+PQ3rspu3uvumY1uI1y7xtX/rfr9cze5No7VX7vE0u96aBTrSmbLxrnXJ9/ubviLPoTVX7nrGvpXd3xFBbx7iXufy/4D3S6E//3aNb5rhft8jrF63wZRX6rQDqehXKfxTP8HfPs4e968hIVrNvHU0DjO3/GG25Yxb/9+2emwexOc86j/yQFcgqgocz2Iti5yr5MGuNJFryvcPsP+dvC3eYC4jgf2BmrdG7YtdTfT5h2gcQtXEont6LZX1f6wT1CwK3FouXuyOjq+mv2C3DMUwWEw/nfuZpq/A5Z/6qp1whv7d929rwLEJZpVE2DQ7a66p8u5cPMULzkAPS5xN/Qpj7leWP1ucMnhUJomw5l/glu+c70qE7q5dp9Tf+/WXfcpnPOIaye5a7k7x7w39rdprJoAWStgxPNwwi9cEr70TddmtOEH1+B/jNXrBBEREUF2dna9v3mqKtnZ2UREHJsJ2E0tt20p/PA8JYknEZW3lndiXuUX2551N/FuI1zVSJkbnpvNc9zv5COc7zx5oGtMXjdtf8JJ8qqphz4O142H5MrTu1SjVW8oL4b0Ke7bPbjEcuof3LMIcZ0PfXx7r5NG3+sOvV+TVi62TTNh4buw4G0oL3Hf1v0Vk+TaD1Z/7brenlTNTMehES6ezDRXwkq9ser9jlZwKJx+r6uSm/emWzfzeZdkul/ss18I/OJ1uOLdA6uijpF6XcWUlJRERkYGWVlZgQ6lxkVERJCUlBToMExNqyh3zylENuNPYffTqPwLHit+083efs6j0DwFVox3SSSpH2ya7apoYjsd2XlCI/f3IIptD81SXFdYcN+o25/h/3u17uO90P0JAqDPNe7ncHpfDU1aew2/h9HnGlj8kRv6IyTSlYTiD5OAKut7nXvg7+TbD27A95X6K9cduNsFLr5jrUUP6DjEVcW16e+S/bn/d3B34OAQaupWXq8TRGhoKCkpKYEOw5hjJ200ZKaxafCzjP26kHuG3goSB1sWucbnvd6XoYy5LkFsnuOqhoKOorKg/WCY8ijsyXCNpkereXv3TETx7gMThL9CwqCzn+cXgQuegZdPdt1A9z2MdyS6XgBXvHf4a26a7EpShysB/Ryn3AlvX+B6U0U2O/SQJTWgXlcxGVOvFOfB1L9Byum8X3ASIUHCtQPbuXrtqz921RJNWkOTRFctVJADO1f7XxVU2b4eREW7XS+boyUCiX1cXE2Pw5PKcZ1cPX7yyYdu36hOUJBrAD5cmwJAymmuTaWmtDvVlcAKd8GAUUc/Uu5RsgRhTF0x9zUozEHPepivlm7n5I5xxDSqYjjspP4uQWye65bbHGH7wz6tTnT18LC//eFonfeUqyc/XnNSD7wVfvVVjdTLH1cicOaDENfFJYjjzBKEMXVB0R6Y+W/oNJRlQZ3ZlFPAeSe0rHrfpP6uK+SK8e7Btp/aAI7Qvh5EIZH+j5ZanbhO7hkJc+Q6nQO3z93fBnQc1es2CGPqjbmvumqGwffz9dJtBAcJQ3scIkGAezCr1YkQ1qjq/fwx5DHXGFvdxD2mXqvREoSIDBeRVSKSLiL3V7E9WUSmishCEVksIuf5bHvAO26ViPyMFjJj6riiPTDzBeh8Ltq6LxOWbGVg++Y0j6qmjrzVie6hsvKSo69e2qd5ihtawzRINZYgRCQYeBE4F+gOXCki3Svt9iBuruo+wEjgJe/Y7t5yD2A48JL3fsY0PD9+CEW5cMYfWb09n3U793LuCa2q3z80Yv+Q3G0GHJcQTf1UkyWIAUC6qq5T1RJgDHBRpX0U2NfROAbY4r2+CBijqsWquh5I997PmIZF1Y0N1Ko3JLrSgwgMq656aZ991UxH+oCcMT5qsg0iEdjss5wBVO5v9wgwSUTuAKKAfU/CJAKzKx2bWPkEIjIKGAWQnJx8TII2plbZstCNg3T+0+QXl/HB3E2c3CGW+Mbhhz7u5DvcWEmND5NIjDmEQPdiuhJ4S1WTgPOAd0XE75hU9TVVTVXV1Pj4asZoMaYuW/iu60XU8zJenb6WrLxi7h7a5fDHxSTtnxvamKNUkyWITKCNz3KSt87XTbg2BlR1lohEAHF+HmtM/VZSAEvGQveL2FIUxuvfr2PEia3pm3yYqTWNOUZqsgQxD+gkIikiEoZrdB5faZ9NwNkAItINiACyvP1Giki4iKQAnYC5NRirMbXP8s+geA/0vY6nJq6iQuGPw/0oPRhzjNRYCUJVy0TkdmAiEAyMVtVlIvIYkKaq44G7gddF5A+4Busb1A29ukxEPgaWA2XAb1X12I9la0xttuBtaN6B1RE9Gbfwe24d3IGkZj/jmQZjjlCNPiinqhOACZXWPezzejlwSjXHPgE8UZPxGVNrZcx3k9QM+xvTVrsB+G48pV1gYzINTqAbqY0xVZn5nBsBte91zF2/i5S4KBIa23wf5viyBGFMbZO9FpaPh/43UREazfyNOaS2tYZpc/xZgjCmtpn1ohv76KRbWJuVz66CUvqnNA90VKYBsgRhTG2SnwWL3ocTR0Ljlszd4OYjHtDOEoQ5/ixBGFObLHwXyopg0B0ApG3YRVx0OG1jrfeSOf4sQRhTW6i6+ZTbDPxpHuW563MYkNIMOV4T7RjjwxKEMbXFtsWQtRJ6XQ7AltxCMnMLSW1r1UsmMCxBGFNbLP7YzePQ4xIA5u1rf7AGahMgliCMqQ0qyt0McJ2HQSOXEOZtyCE6PISuLRsHODjTUFmCMKY2WD8d8rf/VL2kqsxcm02f5KaEBNt/UxMY9i/PmNrgx48gIgY6udl1l2TuZl3WYWaOM6aGWYIwpjZY/RV0vdBNFwqMnZ9BWEgQ5/eyBGECxxKEMYFWsheKdkNcRwCKy8oZ/+MWhnZvQUxkaICDMw2ZJQhjAi1/h/sdlQDA1JU7yC0o5dJ+SQEMyhhLEMYE3l43nDfRLkGMnZ9JfONwTusYF8CgjLEEYUzg5W93v6Piyc4vZtqqHVzSJ9F6L5mAq9F/gSIyXERWiUi6iNxfxfZnRGSR97NaRHJ9tpX7bKs8Vakx9ce+KqboBCYu205ZhXJJn8TAxmQMNTijnIgEAy8CQ4AMYJ6IjPdmkQNAVf/gs/8dQB+ftyhU1d41FZ8xtca+KqaoeOZvXE5sVJg9HGdqhZosQQwA0lV1naqWAGOAiw6x/5XAhzUYjzG1U/4OiGwGwaEs3LSLPsk2OJ+pHWoyQSQCm32WM7x1BxGRtkAK8K3P6ggRSROR2SJycTXHjfL2ScvKyjpGYRtznO3dAVEJ7Npbwrqde+nbtmmgIzIGqD2N1COBsapa7rOuraqmAlcBz4pIh8oHqeprqpqqqqnx8fHHK1Zjjq38LIhOYOHmXQD0TbbpRU3tUJMJIhNo47Oc5K2rykgqVS+paqb3ex0wjQPbJ4ypP/bugOgEFmzMJThI6JUUE+iIjAFqNkHMAzqJSIqIhOGSwEG9kUSkK9AMmOWzrpmIhHuv44BTgOWVjzWmXsjPgqgEFmzaRbdWjWkUVmN9R4w5IjWWIFS1DLgdmAisAD5W1WUi8piIjPDZdSQwRlXVZ103IE1EfgSmAk/69n4ypt4oLYSSPCqi4vlxc65VL5lapUa/qqjqBGBCpXUPV1p+pIrjZgI9azI2Y2oF7xmIbWWN2VtSbgnC1Cq1pZHamIbJewZiVX4kYA3UpnaxBGFMIHkliIW7QomNCqNN88gAB2TMfpYgjAmkvS5BzN4ebA/ImVrHEoQxgZTvqpgW5YQyIMWql0ztYgnCmEDK305JSBNKCOX0zvawp6ldLEEYE0h7d5AjMSQ0DqdLCxugz9QuliCMCSDN30FGaTSndYq39gdT61iCMCaAindvZ1t5E07vbLPHmdrHEoQxAST5O8gmhlNtelFTC1mCMCZQSosIL88nKLoFsdHhgY7GmINYgjAmQPJytgKQ0CopwJEYUzW/EoSIjBOR80XEEooxx8iSVWsAaNc2JcCRGFM1f2/4L+Em7lkjIk+KSJcajMmYBmHDxg0AtG9nCcLUTn4lCFX9RlWvBvoCG4BvRGSmiNwoIqE1GaAx9VX2djcjb2iTFgGOxJiq+V1lJCKxwA3Ar4GFwHO4hDG5RiIzph4rys+l057ZbiE6IbDBGFMNv+aDEJFPgC7Au8CFqrrV2/SRiKTVVHDG1EvLPiXoi3sZHrSDDZ1/RbtQG8HV1E7+liCeV9Xuqvp3n+QAgKqmVneQiAwXkVUiki4i91ex/RkRWeT9rBaRXJ9t14vIGu/nen8vyJhaLW87jL2R3cHNuaj4MaJHPBnoiIyplr8zynUXkYWqmgtuzmjgSlV9qboDRCQYeBEYAmQA80RkvO/Uoar6B5/97wD6eK+bA38BUgEF5nvH7jqSizOm1tmyALSCt5rcxq6KZOLs+QdTi/lbgrh5X3IA8G7UNx/mmAFAuqquU9USYAxw0SH2vxL40Hs9DJisqjneuSYDw/2M1Zjaa8siVIL4fEcsfZObBjoaYw7J3wQRLD4jiXmlg7DDHJMIbPZZzvDWHURE2gIpwLdHcqyIjBKRNBFJy8rKOuxFGBNwWxZS1rwTm/KFvm1t/gdTu/mbIL7GNUifLSJn477pf30M4xgJjFXV8iM5SFVfU9VUVU2Nj7ex9E0tpwpbFrItqhtg80+b2s/fBHEfMBW41fuZAvzxMMdkAm18lpO8dVUZyf7qpSM91pi6IW8r7N3BEm1PRGgQXVra/A+mdvOrkVpVK4CXvR9/zQM6iUgK7uY+Evc09gFEpCvQDJjls3oi8DevMRxgKPDAEZzbmNpny0IApuUl0SupKaHBNnKNqd38HYupk4iMFZHlIrJu38+hjlHVMuB23M1+BfCxqi4TkcdEZITPriOBMaqqPsfmAH/FJZl5wGPeOmPqri0LUQlmQlasVS+ZOsHfbq7/wXU7fQY4E7gRP5KLqk4AJlRa93Cl5UeqOXY0MNrP+IypfXamw4yn4fR7oHl72LKQ3dEdyM8K5ayu9vS0qf38LeNGquoUQFR1o3dTP7/mwjKmjlv1Fbx+Jix6Hz79LVRUwJZFpJW2o2NCNP3bWQnC1H7+Johib6jvNSJyu4hcAkTXYFzG1F2zX4EPR0LzFBj8J9g0E6b9HQp2Mi0vkasGJNv806ZO8LeK6U6gEfA7XNvAmYANf2FMZXnb4Ju/QKdhcPnbEBIB66fDd/8EYKV04J6+VT4OZEytc9gShPdQ3BWqmq+qGap6o6peqqqzj0N8xtQtM56F8lI490kIjQQRuOBZNDiMUg2mfY8BNG10uGdMjakdDluCUNVyETn1eARjTJ22ZyukjYYTr3SN0vvEd2Z+t/tYsmguvxzUKXDxGXOE/K1iWigi44H/Anv3rVTVcTUSlTF10YxnQMtdryUfBSVl3JnelybxJ3GDDa9h6hB/E0QEkA2c5bNOAUsQxgDs2QLz3/JKDwdOIfrcN2vIzC3k2ZG9rXHa1Cn+Pkl9Y00HYkydNv9tKC+B0+4+YPXyLXt4Y8Z6RvZvQ/92zQMUnDFHx98Z5f6DKzEcQFV/dcwjMqYuKCuBEK+xuaLcPe/Q4cwDSg8VFcqfP11C08hQ7j+3a4ACNebo+fscxBfAl97PFKAJkF9TQRlTqy37FP6ZAlmr3PK6qbB7M/S59oDdxi3MZOGmXP50XjfruWTqJH+rmP7nuywiHwIzaiQiY2q7zXOhJB8+/z3c8CUseBcim0PX/YMLFJaU89TEVZzYpim/sOceTB11tMNJdgJsMBnTMO1cDUGh7gnpH56FlV/CiSMhZP/0oW/OWMe2PUX8+bxu1jBt6ix/2yDyOLANYhtujghjGp6dq6H7CMjfAVMedet8qpey8op5edpahvVowYAUa5g2dZdfJQhVbayqTXx+OleudjKmQSgthNxNENcFLngGgsMgsR+06P7TLv/4eiXFZRXcN9wapk3d5m8J4hLgW1Xd7S03BQar6qc1F5oxtVB2OqAQ3xniOsG1n0DU/trWd2dvZOz8DH57Zgfax9t4lqZu87cN4i/7kgOAqubi5ocwpmHZ13MprrP73e5UlyyAmek7eWT8Ms7qmsBdQ7oEKEBjjh1/E0RV+/n7FLYx9cfONSBB0LzDAaszcwu57YMFtI+L4rmRvQkOsoZpU/f5myDSRORpEeng/TwNzD/cQSIyXERWiUi6iNxfzT6Xe1OZLhORD3zWl4vIIu9nvJ9xGlOzdq6Gpm0hNOKA1c9OXk1BSTlvXJ9K44jQAAVnzLHlbyngDuAh4CNcb6bJwG8PdYA3TPiLwBAgA5gnIuNVdbnPPp2AB4BTVHWXiPh2nS1U1d7+Xogxx8XO1furlzwbdu5l3MJMrhvUlraxUQEKzJhjz98H5fYCVZYADmEAkK6q6wBEZAxwEbDcZ5+bgRdVdZd3nh1HeA5jjp+KctdI3eHMA1b/+9t0QoKEW8/oUM2BxtRNflUxichkr+fSvuVmIjLxMIclApt9ljO8db46A51F5AcRmS0iw322RYhImrf+4mriGuXtk5aVleXPpRhz9HI3QVnRASWI9Tv38snCDK4Z2JaEJhGHONiYusffKqY4r+cSAFVUB/2c83cCBgNJwHci0tM7V1tVzRSR9sC3IrJEVdf6HqyqrwGvAaSmph40mKAxx9TONe63lyBUlX9NWkVYSBC/sdKDqYf8baSuEJHkfQsi0o4qRnetJBNo47Oc5K3zlQGMV9VSVV0PrMYlDFQ10/u9DpgG9PEzVmNqxs7V7ndcZ1SVJ79ayReLt/KbMzoQ3zj80McaUwf5myD+DMwQkXdF5D1gOq5x+VDmAZ1EJEVEwoCRQOXeSJ/iSg+ISByuymmdV4UV7rP+FA5suzDm+Nu5ChrFoZHN+OfEVbz63TquHdiWO8+2aURN/eRvI/XXIpIKjAIW4m7shYc5pkxEbgcmAsHAaFVdJiKPAWmqOt7bNlRElgPlwL2qmi0iJwOvikgFLok96dv7yZiA2LkG4joz/sctvDxtLVeflMxjF/WwwfhMvSWqh6+6F5FfA3fiqokWAQOBWap61qGOO55SU1M1LS0t0GGY+qq8DJ7qCN1GcFPOtazclsf3fzyTIHsgztRxIjJfVVOr2uZvFdOdQH9go6qeiWsPyD024RlTB6wYD4W7KGp3Ft+n72RYj5aWHEy952+CKFLVIgARCVfVlYANNmMaBlX44Tlo3oGppFJSVsHQHi0CHZUxNc7fbq4Z3nMQnwKTRWQXsLGmgjKmVtnwPWxdBBc8y8TlWTRrFEpq22aBjsqYGudvI/Ul3stHRGQqEAN8XWNRGVOb/PA8RMVT2vMKpnzxPcN6tCQk+GgnYzSm7jjiEVlVdXpNBGJMrbR9GaRPhrMeZM6mAvKKyhja3aqXTMNgX4OMOZSl40CCIfUmJi3fRmRoMKd3jg90VMYcF5YgjDmUwl0Q2QwaNeeb5ds5vXMcEaHBgY7KmOPCEoQxh1KcB+GNySsqZcvuIvokW+O0aTgsQRhzKF6C2JJbBEBi08gAB2TM8WMJwphDKc6D8CZk5hYAkNjMEoRpOCxBGHMoxXsgvDGZu9zQY1aCMA2JJQhjDsWrYsrILSQsOIj4aBvW2zQcliCMORQvQWTuKqRV0wgbf8k0KJYgjDmUfQkit9Cql0yDYwnCmOqUFUN58U8lCEsQpqGxBGFMdYrzASgNjWZHXrH1YDINTo0mCBEZLiKrRCRdRO6vZp/LRWS5iCwTkQ981l8vImu8n+trMk5jqlS8B4Dd5REAtLYShGlgjniwPn+JSDDwIjAEyADmich436lDRaQTbm7rU1R1l4gkeOubA38BUgEF5nvH7qqpeI05SHEeADtLwwBIsgRhGpiaLEEMANJVdZ2qlgBjgIsq7XMz8OK+G7+q7vDWDwMmq2qOt20yMLwGYzXmYF4JYluxSxBWxWQamppMEInAZp/lDG+dr85AZxH5QURmi8jwIzgWERklImkikpaVlXUMQzeGn0oQWwpCEIFWMZYgTMMS6EbqEKATMBi4Enjdm7nOL6r6mqqmqmpqfLwNwWyOMS9BbCoIIaFxOGEhgf7vYszxVZP/4jOBNj7LSd46XxnAeFUtVdX1wGpcwvDnWGNqllfFtCEvyLq4mgapJhPEPKCTiKSISBgwEhhfaZ9PcaUHRCQOV+W0DpgIDBWRZiLSDBjqrTPm+PFKEOvygkhs1ijAwRhz/NVYglDVMuB23I19BfCxqi4TkcdEZIS320QgW0SWA1OBe1U1W1VzgL/iksw84DFvnTHHT3EeKsFs2F1B66YRgY7GmOOuxrq5AqjqBGBCpXUP+7xW4C7vp/Kxo4HRNRmfMYdUnIeGNaakUK2Lq2mQrNXNmOoU51EaGgVYF1fTMFmCMKY6xXkUB3kJoqm1QZiGxxKEMdUp3sNeXGKwEoRpiCxBGFOd4jz2aATNGoUSHV6jzXXG1EqWIIypTnEe2aXhtIuLCnQkxgSEJQhjqlOcx46SMFIsQZgGyhKEMdVQL0G0twRhGihLEMZUpbwMKS0gTyOtisk0WJYgjKlKiRtmI59Iq2IyDZYlCGOqUrw/QbSLtQRhGiZLEMZUxUsQwZFNiLIurqaBsgRhTFW8BBHdpHmAAzEmcCxBGFMVL0E0b24JwjRcliCMqULBnl0AxDaPC3AkxgSOJQhjqrAzJxuAlgkJAY7EmMCxBGFMFfbk7gQgsYUlCNNw1WiCEJHhIrJKRNJF5P4qtt8gIlkissj7+bXPtnKf9ZWnKjWmRuXv3kWFCm1aWhWTabhqrP+eiAQDLwJDgAxgnoiMV9XllXb9SFVvr+ItClW1d03FZ8yhFO3NpUAiiQ4NDXQoxgRMTZYgBgDpqrpOVUuAMcBFNXg+Y36ewl2QuxmA0oI9FAfbJEGmYavJBJEIbPZZzvDWVXapiCwWkbEi0sZnfYSIpInIbBG5uKoTiMgob5+0rKysYxe5aZi+ug/eHIqWl6FFeygPjQ50RMYEVKAbqT8H2qlqL2Ay8LbPtraqmgpcBTwrIh0qH6yqr6lqqqqmxsfHH5+ITf2VkQZ5W9i1YjoRFQUQ3iTQERkTUDWZIDIB3xJBkrfuJ6qararF3uIbQD+fbZne73XANKBPDcZqGrriPMhZB0Degv/SWAqJiI4JcFDGBFZNJoh5QCcRSRGRMGAkcEBvJBFp5bM4AljhrW8mIuHe6zjgFKBy47Yxx8725YBCo1hiN31NU8m3YTZMg1djvZhUtUxEbgcmAsHAaFVdJiKPAWmqOh74nYiMAMqAHOAG7/BuwKsiUoFLYk9W0fvJmGNn22L3+7R7iJ74ANECRDQOaEjGBFqNDlOpqhOACZXWPezz+gHggSqOmwn0rMnYjDnA9qUQ0ZTi3tdS9vUjREmxtUGYBi/QjdTG1A7blkDLnizLKmNKRV+3LtxKEKZhswRhTHkZbF8GLXuxYOMuviwf6NZbgjANnCUIY3LWQlkRtOzJgk27WNNkIPS4BFJOD3RkxgSUTZVlzLYlAGjLE5g/YTsD27eAX74V2JiMqQWsBGHMtsUQHMaW0GS27ymmb3KzQEdkTK1gCcKYbUshvivzM/YC0K+tJQhjwBKEMT/1YJq1dieRocF0bWmN08aAJQjT0OVth7072BzegY/mbWbEia0JCbb/FsaAJQjT0G2aCcCTPzaiVUwkf76gW4ADMqb2sF5MpmFLn0JhUDQTdyfy3s0n0iTCJggyZh8rQZiGS5WilZP4trQ7N57akYHtYwMdkTG1iiUI02BtWJFGROF21scM4p5hXQIdjjG1jiUIU++VlFVQUaEHrNtdUMpXn74HwOUjbyA8JDgQoRlTq1kbRA1QVSoUgoPkkPsVlZazYOMuBnWIReTQ+1Zl7vocurduQnS4fYzVWbM9j+tGzyVIhKtOSuacbi34bnUWY+Zt4rGiNAqadyEhqX2gwzSmVrISRA149PPlDHv2O4pKyw+5339+2MBVb8xh6qodR3yO1dvzuPzVWfx7ypqjDfOY+N2HC/ndhwspLa8IaBxV+XFzLpe/OovScqVtbCP+b+Iqhj37HU9MWEFsWBmDQlbRqNuQQIdpTK1lXz2PsfziMj5O20xBSTkvTVvLXUM6V7vvhCVbAXj8yxWc1ime0CPof//2zA0AfLF4K/ef2/WoSiA/15x12Yz/cctPy89c0fuwpSZ/LM3czbRVO/h+zU66tWrCwxd0J8iP980tKOHFqelk7CqktFyZtXYnzaLCeO+mk2gXF0X6jnxmrcvmlA6xtN/1A3xQCh3P+dnxGlNfWYI4xsYv2kJBSTm9kmJ4ZdpaLumTSEpc1EH7bc4pYEnmbk7pGMsP6dm8P3sjN5yS4tc5dheWMm5BJvGNw8nMLeTHjN30btP0GF/J4T3/7RriosO5dmBbnvlmNY0jQnj84hN+VrIaPWM9j33hJg9MiYtizvoNhAQJfz6/2yHf96slW3nos2XkFpSQEhdFSHAQJ7WP5W+X9KRlTAQAHWOgY/mnsLwY1k2H0EaQPOioYzWmvqvRBCEiw4HncFOOvqGqT1bafgPwf0Cmt+oFVX3D23Y98KC3/nFVfbsmYwUgdxNsXQzdLqh6+7ppEJUALbofvK28FBa+S/n0hfylqXLJGedz2tggHv5sKe/8asBBN7evl26jKXk8130Xv9f2PPPNGi7uk0jTkFJY+B4U57kd250KyQMPOHbs/AwKS8t58/pUrv/PXL5LW0TvPbnQ/SI41M25pMB77z0/rcreW8K4BRn0a9ecvm2aQosToMvww/6p0jbk8EN6Nv8+uZALu8dRWNqBV6avpX+75lzcKgcKcyHltP0H5KyDZZ+CVkBQMPS8HGISD3jPRZtz+fdX83mwzRouuvoO4mKiePTz5bwxYz1NIkM5rVMcm3IKSGoWSb82TWHZOLT9YP767Q5G/7CeExKb8M6vBtC9dTUzwS0bB5Mf3r984pUQGnHYazWmoRJVPfxeR/PGIsHAamAIkAHMA670nVvaSxCpqnp7pWObA2lAKqDAfKCfqu6q7nypqamalpZ29AHv3QmvnwW5G1k38G/8aVNfLu2bxC9T27jtaybDB5dDRAz8egrEdth/rCp8fics8M1hwpQTn+GmOQl0bdmY+Mbh9Ggdwz1DOxMSHMTIF7/lkZz76Vq+ip29f8uAOadwbo8Eng96muDV+2dprQgKpeK68YS0O9ktVyhn/WsasdHh/O/Wk7njzW+5J+N22momDH8SBt5a9fVVVMB/r4cV4w/7pyj/xZukJwyjXVyjanv3XPvmHMIzZ/M6f0VCwqm48Wsu+DiX5gXreJc/I6WFcM04aH8G5G1zf9s9mfvfILYj/PobiHQD4+0uLOWi56fyVPFjpFYsgdSb4Px/UaHw+48WHVCVJQKfdP6G3htHs61xD87IupeRgzrx0AXdDz1Mxvg7YPl4uHetexMJOnRCNaYBEJH5qppa1baabKQeAKSr6jpVLQHGABf5eewwYLKq5nhJYTJw+K+1R6usGD66Bs3bztqI7rSZ9RAhG7/nwU+XsjYrH7Yvh//eCPHdAIEProBCn1w1+yVY8DbTE66lR9l75N65DhL7ctbyP/PogAoSm0ayp7CUV6av5R9fr2RrbgFXbfsnXctXQbvTiFv0Im+cuIaeK58jePUENg14mDs7TaJf0ctsKIsl760reGfCdD5blMkLU9PZkF3A9Se3g/JSHir8B60qtpGfkAoT/wSrJ1V9jVOfcMlh6BPwYBY8mMWTqd/TqegdJl26hLu6TKZb0WiWh55A6bjfcN9zo7n81dlk5xcf9FZz1+ewMX0Z/w5+GmnWFsIbEzTmSh4dFMQThY9TqGHQvAN8fK0rkX14pStRjJruzn3DBFda+/g6V/ICHvxkCbfkv+KSQ7vTIO1NmPsaQUHCU788kX9f2YfXr0vlqztP4y9tFtN742iWhfUiYc9yxiS8w18u6EbIyvHwQn/49nGXtCvLSIOk/hAc4koxlhyMOaSaLEFcBgxX1V97y9cCJ/mWFrwSxN+BLFxp4w+qullE7gEiVPVxb7+HgEJVfarSOUYBowCSk5P7bdy48cgDVYVPb4UfP+Sh0Hv4uqgHXzf+K83Ks3m6+CKaRUXwq9CvkbISuPlbyN1IxdsjWBvWlZXNz6RVaCH9Nr7BmuZncln2KM7q1pJnR/bZ/60ZYNDtIMJXS7Yyd0MOZ8TsYHDBRLIH/YnYc+6C9y6FDTNAyxnDMO4vup6wkCBuG9yBftHZ9Jl4GVvKY/iw3L1fTEQot5/diZCMObD8U+4r/w1hvX7BHRvvoFH+JsZEXkm/lHhOSIxxDd95W+GH56Dv9XDhcyDCjDU7uebNOVwzMJnHL+5JeYXyxJcrmL8yndEl9xEpxTxbeD5NIsO4+qRkmkWFAe6Zgte+W8cFpV/RNrwAuXmKqw77z7loWTGlGszNQY/w0i3DiXp7qEukWgFXfghdzgWgrLyCkCUfwae/gW4jyIzpwzczZnJ9yGQ49S446yGXXFZNgNP/CJFN939eJXvRaU+yIaoXQ7Lu5O+tvueXu153CSlnLUTFw94sOPl3MOSx/UmgaA88mQyDH4DB9x35vxNj6qlDlSACnSBigXxVLRaRW4ArVPUsfxOEr6OuYtq5hopXTuX1iot4VX7JO78awAmNdsHocyHPVWsUB0cTcuPnSOs+vPb9OtInv86TIa8RguvGOr+iE9eWPkBUdAxvXp9Kr6Sm7r23LoZ3RhxY2vB8GTaM8x/4yN3ACnfBWxdATBKbh77O+/O2cEX/Nvsbt9dNp+LDkQSVFhwc/+n3cnPGcCYv305Lsvk86gniy7cdtFte0mAa3zgWgkNZnJHL1W/MoUWTCD6//VQiwypVI2Wtgv+cBwU7q/2zlYc0Ivia/7o2EoAVn8Ont7Hx5L9xxlfNubRvEje02UaPaTcTNPg+GPRbAKas2M4fPlrEtYPacm/YOJj+j5/es7TbJYT+cjQEBUHJXnh7BGRW8Zkm9IAbv2RpThCdEqII//pu175x1oPQ7wb4+n6Y9wacfAcMfdwds3YqvHuxq/bqeHa112VMQxOoBDEIeERVh3nLDwCo6t+r2T8YyFHVGBG5Ehisqrd4214Fpqnqh9Wd72gTxIade7njxbHsCGnN+zcPpGOCNxdAeSmU5HPP2MWMX7YLDQ4jJjKMnfnFnNezJU9e2IEmoUpecRklwdE0jYqouotnWTH43NhzC0q57YNFjDipKyMHJO/fr6L80HXipYVu3mRfEgwRTVi0OZcP5mzkmoFt6dUqCi3OZ+76HL5auo3lW/aQnpXHLm3E9YNSGH5CS0a9k0ZMo1DGjBpEYtPIqs9XVgKle1m/cy93ffwj63bmc2GvRMb/mMlVA5K5/8I+BzfwVpRDUDD3/28xY+ZtBiCICvq2jeXaQW3ZnFPAvyavJioshPziMt676STiQou5/JUZ3Dq4E7cO71vp/SqgePfBsYU3cVVE+6jub/zet/zlXZA2Gm75DlqdCNP/D6Y+DvdtPLBEYkwDF6gEEYKrNjob10tpHnCVqi7z2aeVqm71Xl8C3KeqA71G6vnAvjvGAlwjdU515zvaBFFWXsHjX67gV6ekkBzb6KDtBSVlfLZoC5tyCtiaW8hJ7WMZ2b9NQJ47OFp7ikr518RVvDN7I6qQ1CySMaMGktTs4OutSkFJGQ9+upRxCzJpHxfFl7877eBShw9VZfueYtZm5bM4YzcfzdvEhmyXJC/q3ZpHLuzBZa/MJL+4jC4tm7Bw4y5m3H8WMZHHcCTVwl3wVBfoex2c/xS8fzns2gC3zz125zCmHghIgvBOfB7wLK6b62hVfUJEHgPSVHW8iPwdGAGUATnAraq60jv2V8CfvLd6QlX/c6hz/exeTA3Agk27GDN3E3ec1Yk2zf1LDr6mrtpBx/joIz62okKZkb6TgpJyhvVogYiwNHM3l7z0A6Xlyh1ndeTuoTUwWN7/fu0a7e9eCc/0gK7nwUUvHvvzGFOHBSxBHE+WIOqed2Zt4K0fNvC/W0/+qRH8mFr/Hbx9oWuYnvZ310Df74Zjfx5j6rBDJQh7ktoEzHWD2nHtwLY1V13X9lRo1g6+f9otJ/WvmfMYU0/ZYH0moGq0LScoCPpcA+XFEBYN8V1r7lzG1EOWIEz91vtq1zssse+BPZ+MMYdlVUymfmvSGs79pxvawxhzRCxBmPpvwM2BjsCYOsmqmIwxxlTJEoQxxpgqWYIwxhhTJUsQxhhjqmQJwhhjTJUsQRhjjKmSJQhjjDFVsgRhjDGmSvVmNFcRyQKOYs7Rn8QB1U+hVrfYtdROdi21U326Fjjy62mrqvFVbag3CeLnEpG06oa8rWvsWmonu5baqT5dCxzb67EqJmOMMVWyBGGMMaZKliD2ey3QARxDdi21k11L7VSfrgWO4fVYG4QxxpgqWQnCGGNMlSxBGGOMqVKDTxAiMlxEVolIuojcH+h4joSItBGRqSKyXESWicid3vrmIjJZRNZ4v5sFOlZ/iUiwiCwUkS+85RQRmeN9Ph+JSFigY/SXiDQVkbEislJEVojIoLr62YjIH7x/Y0tF5EMRiagrn42IjBaRHSKy1GddlZ+DOM9717RYRPoGLvKDVXMt/+f9G1ssIp+ISFOfbQ9417JKRIYd6fkadIIQkWDgReBcoDtwpYh0D2xUR6QMuFtVuwMDgd968d8PTFHVTsAUb7muuBNY4bP8D+AZVe0I7AJuCkhUR+c54GtV7QqciLuuOvfZiEgi8DsgVVVPAIKBkdSdz+YtYHilddV9DucCnbyfUcDLxylGf73FwdcyGThBVXsBq4EHALx7wUigh3fMS949z28NOkEAA4B0VV2nqiXAGOCiAMfkN1XdqqoLvNd5uBtQIu4a3vZ2exu4OCABHiERSQLOB97wlgU4Cxjr7VKXriUGOB14E0BVS1Q1lzr62eCmJ44UkRCgEbCVOvLZqOp3QE6l1dV9DhcB76gzG2gqIq2OS6B+qOpaVHWSqpZ5i7OBJO/1RcAYVS1W1fVAOu6e57eGniASgc0+yxneujpHRNoBfYA5QAtV3ept2ga0CFRcR+hZ4I9AhbccC+T6/OOvS59PCpAF/MerMntDRKKog5+NqmYCTwGbcIlhNzCfuvvZQPWfQ12/J/wK+Mp7/bOvpaEniHpBRKKB/wG/V9U9vtvU9WOu9X2ZReQCYIeqzg90LMdICNAXeFlV+wB7qVSdVIc+m2a4b6MpQGsgioOrOeqsuvI5HI6I/BlX7fz+sXrPhp4gMoE2PstJ3ro6Q0RCccnhfVUd563evq9Y7P3eEaj4jsApwAgR2YCr6jsLV4ff1KvWgLr1+WQAGao6x1sei0sYdfGzOQdYr6pZqloKjMN9XnX1s4HqP4c6eU8QkRuAC4Crdf/DbT/7Whp6gpgHdPJ6Y4ThGnTGBzgmv3l19G8CK1T1aZ9N44HrvdfXA58d79iOlKo+oKpJqtoO9zl8q6pXA1OBy7zd6sS1AKjqNmCziHTxVp0NLKcOfja4qqWBItLI+ze371rq5Gfjqe5zGA9c5/VmGgjs9qmKqpVEZDiuanaEqhb4bBoPjBSRcBFJwTW8zz2iN1fVBv0DnIdr+V8L/DnQ8Rxh7KfiisaLgUXez3m4uvspwBrgG6B5oGM9wusaDHzhvW7v/aNOB/4LhAc6viO4jt5Amvf5fAo0q6ufDfAosBJYCrwLhNeVzwb4ENd2Uoor2d1U3ecACK5n41pgCa7nVsCv4TDXko5ra9h3D3jFZ/8/e9eyCjj3SM9nQ20YY4ypUkOvYjLGGFMNSxDGGGOqZAnCGGNMlSxBGGOMqZIlCGOMMVWyBGFMLSAig/eNYGtMbWEJwhhjTJUsQRhzBETkGhGZKyKLRORVb/6KfBF5xpsvYYqIxHv79haR2T7j9O+bc6CjiHwjIj+KyAIR6eC9fbTP/BHve08tGxMwliCM8ZOIdAOuAE5R1d5AOXA1bvC6NFXtAUwH/uId8g5wn7px+pf4rH8feFFVTwROxj0ZC2403t/j5iZpjxvvyJiACTn8LsYYz9lAP2Ce9+U+EjfIWwXwkbfPe8A4bz6Ipqo63Vv/NvBfEWkMJKrqJwCqWgTgvd9cVc3wlhcB7YAZNX5VxlTDEoQx/hPgbVV94ICVIg9V2u9ox68p9nldjv3/NAFmVUzG+G8KcJmIJMBP8xq3xf0/2jeq6VXADFXdDewSkdO89dcC09XN/JchIhd77xEuIo2O50UY4y/7hmKMn1R1uYg8CEwSkSDciJq/xU0GNMDbtgPXTgFuGOlXvASwDrjRW38t8KqIPOa9xy+P42UY4zcbzdWYn0lE8lU1OtBxGHOsWRWTMcaYKlkJwhhjTJWsBGGMMaZKliCMMcZUyRKEMcaYKlmCMMYYUyVLEMYYY6r0/53qwXX5DzpvAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRdpYWU9ovQ"
      },
      "source": [
        "### Evaluating on Given Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": true,
        "id": "3FKFdP0j9ovQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6329ced5-aa6e-4cdd-acf0-779885fa776a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "k_a4IvMB9ovQ",
        "outputId": "d378e1df-1b5c-4ae2-9563-747a89d03f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "test_data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nX4PCu_49ovR",
        "outputId": "fb5e9d2a-9450-4ee0-ddd9-a6382245a46c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ],
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "2kfYa4-t9ovR",
        "outputId": "5b25094f-56c1-4ef0-da09-a08aed9b774d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ],
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "_vgjW9ss9ovR",
        "outputId": "2eae14e3-de3e-4780-c1ad-7beb41b3575f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ],
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "BZHHwSP09ovS",
        "outputId": "201f7f3b-1438-4deb-acdd-036c84afa518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9999923\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPyrIKF29ovS"
      },
      "source": [
        "## Writing new Stories and Questions\n",
        "\n",
        "we can only use words from the existing vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "EN-4wCEk9ovS",
        "outputId": "cc3a90aa-7e92-43d5-af27-eafc5134ec11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "d2H-qDca9ovT",
        "outputId": "3d6a01f6-267b-4835-d89b-128a84960f1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "collapsed": true,
        "id": "QYzSfjb89ovT"
      },
      "outputs": [],
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "lGKJruFO9ovT",
        "outputId": "4bf4c425-7a0f-45c1-a332-b47192ca8ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "my_question.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "collapsed": true,
        "id": "uTDQZvV_9ovU"
      },
      "outputs": [],
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "collapsed": true,
        "id": "qIKWBw1a9ovV"
      },
      "outputs": [],
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "mF81gKbI9ovV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a448d6f8-967e-4963-e3c9-60e9294034c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 93ms/step\n"
          ]
        }
      ],
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "rd9SbBBn9ovV",
        "outputId": "bc7eb5cb-ec7e-44b7-c8da-159161235387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9072534\n"
          ]
        }
      ],
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ]
    }
  ]
}