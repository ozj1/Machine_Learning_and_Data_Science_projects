{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtbyCsGETuB0wQqyyZURFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozj1/Machine_Learning_and_Data_Science_projects/blob/main/Chat-Bot_natural_language_processing/Chat_Bot_natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data\n",
        "\n",
        "We will be working with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ],
      "metadata": {
        "id": "J-JpZRKJ-Ae-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTkh-4-XRBet",
        "outputId": "1e634924-8e57-4a14-9524-eeb51069c5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0GRWATf2A7Z-",
        "outputId": "4e11bfc7-e740-4abe-dc43-742c6c83e0e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "W-7nlyz69oul"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "V1Mr5f2I9oun"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "sNplFO3P9ouo"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## understanding the dataset format, a short story, a question, and an answer Yes or No"
      ],
      "metadata": {
        "id": "CtJXt0elDjxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_data))\n",
        "print(type(train_data))\n",
        "print(len(test_data))\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBV7H4PED5aa",
        "outputId": "0a6634dc-f254-46f4-fffc-5f8b21c43d3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "1000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehi_BpS6EKmT",
        "outputId": "f91f1d5f-f5b0-4495-f620-83c67b94e7d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping to get the sentence\n",
        "print(' '.join(train_data[0][0]))\n",
        "print(' '.join(train_data[0][1]))\n",
        "#now what is the answer?\n",
        "print(train_data[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3awpdMHqENdr",
        "outputId": "2f69e6a8-9d59-46e9-e222-aaa7056a12f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
            "Is Sandra in the hallway ?\n",
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how many unique words we have in the entire dataset using set() and unite them using union()."
      ],
      "metadata": {
        "id": "raARcfFcE_nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()\n",
        "all_data = test_data + train_data\n",
        "\n",
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "\n",
        "#answer dataset only has two words, we add them\n",
        "vocab.add('no')\n",
        "vocab.add('yes')\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0bP9JaFP3B",
        "outputId": "7479e83a-d724-41ac-84f6-36e22cbad532"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences\n",
        "#we find the max size of a story\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "print(max_story_len)\n",
        "#we find the max size of a question in the dataset\n",
        "max_question_len = max([len(data[1]) for data in all_data])\n",
        "print(max_question_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtXL9fwgFlHJ",
        "outputId": "6aed9410-88e7-4002-8e5b-3421052aca3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We vectorize the data so it can be understood by Keras."
      ],
      "metadata": {
        "id": "NKztrBDXG7_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eTQ3PnHJRp",
        "outputId": "204dfb22-3adf-4886-8dc6-192c880ae0dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'milk': 1,\n",
              " 'john': 2,\n",
              " 'no': 3,\n",
              " 'is': 4,\n",
              " '?': 5,\n",
              " 'kitchen': 6,\n",
              " 'grabbed': 7,\n",
              " 'back': 8,\n",
              " 'daniel': 9,\n",
              " 'took': 10,\n",
              " 'picked': 11,\n",
              " 'to': 12,\n",
              " 'bathroom': 13,\n",
              " '.': 14,\n",
              " 'travelled': 15,\n",
              " 'sandra': 16,\n",
              " 'in': 17,\n",
              " 'went': 18,\n",
              " 'put': 19,\n",
              " 'moved': 20,\n",
              " 'yes': 21,\n",
              " 'garden': 22,\n",
              " 'dropped': 23,\n",
              " 'office': 24,\n",
              " 'mary': 25,\n",
              " 'football': 26,\n",
              " 'apple': 27,\n",
              " 'journeyed': 28,\n",
              " 'down': 29,\n",
              " 'there': 30,\n",
              " 'the': 31,\n",
              " 'bedroom': 32,\n",
              " 'discarded': 33,\n",
              " 'hallway': 34,\n",
              " 'got': 35,\n",
              " 'left': 36,\n",
              " 'up': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "# We make separate lists for story, query, and answer.\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "B39NQvOxHuDy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
        "\n",
        "print(len(train_story_text))\n",
        "print(len(train_story_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezWjYjFpH2gY",
        "outputId": "17350d29-9f9c-4a9d-d799-dd322ac9d389"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functionalize Vectorization"
      ],
      "metadata": {
        "id": "bScJEEHeIbnC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "T5grEdyr9ou9"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "pCRYzkAr9ou-"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "iFPb4OhM9ou_"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p8xQt2UB9ou_",
        "outputId": "d3e42a02-3080-4455-d69e-7d94ace52cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 31, 32, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 31, 27, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 27, 30, 14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6mH0IsXV9ovA",
        "outputId": "7501442a-6368-4019-cf63-880c5b82a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31, 22,  5],\n",
              "       ...,\n",
              "       [ 4, 25, 17, 31, 32,  5],\n",
              "       [ 4, 16, 17, 31, 22,  5],\n",
              "       [ 4, 25, 17, 31, 22,  5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DhaDoUld9ovB",
        "outputId": "5ec10f9c-9eb8-4490-9bf3-a7e94425ecc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "idSgpnbN9ovB",
        "outputId": "887a36f9-e03c-42b1-95ce-fbead1422742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Gi2_q80D9ovC",
        "outputId": "b92ecb97-f4bc-4eee-893f-41b326a7f9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vXD3zd239ovD",
        "outputId": "de8df310-ae09-49de-8c92-129d4c7ed50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0RJITpT9ovD"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": true,
        "id": "R0KQrG9t9ovE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWlJY0gQ9ovE"
      },
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": true,
        "id": "2ChjupFZ9ovE"
      },
      "outputs": [],
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvItdiz49ovF"
      },
      "source": [
        "## Encoders\n",
        "we build the model as described in the paper \n",
        "\n",
        "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  \"End-To-End Memory Networks\",\n",
        "  http://arxiv.org/abs/1503.08895\n",
        "### Input Encoder m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": true,
        "id": "GwDB3MqU9ovG"
      },
      "outputs": [],
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV8TLTkI9ovG"
      },
      "source": [
        "### Input Encoder c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": true,
        "id": "E9Sx1YK39ovG"
      },
      "outputs": [],
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4evnPaZe9ovH"
      },
      "source": [
        "### Question Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": true,
        "id": "ZcxXzVi-9ovH"
      },
      "outputs": [],
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58J0Cg5R9ovI"
      },
      "source": [
        "### Encode the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": true,
        "id": "B4FWaclS9ovI"
      },
      "outputs": [],
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esvE3bZp9ovJ"
      },
      "source": [
        "##### Use dot product to compute the match between first input vector seq and the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "id": "EIDwu68U9ovJ"
      },
      "outputs": [],
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNQ-sD2H9ovK"
      },
      "source": [
        "#### Add this match matrix with the second input vector sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": true,
        "id": "d7MQWcZC9ovK"
      },
      "outputs": [],
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMlPMPgg9ovL"
      },
      "source": [
        "#### Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "id": "aYp-et4a9ovL"
      },
      "outputs": [],
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "F-eq5Knj9ovL",
        "outputId": "cdc78ea6-c392-4409-96c5-20931ceac0d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": true,
        "id": "_TK1sR899ovM"
      },
      "outputs": [],
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # (samples, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "id": "TK4INMhM9ovM"
      },
      "outputs": [],
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "id": "LblmnAPw9ovN"
      },
      "outputs": [],
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "eMXwsjPk9ovN",
        "outputId": "8d9af498-fc8e-4f05-ab34-a22efa3f091b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 64)     2432        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_3 (Sequential)      (None, 6, 64)        2432        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential_1[0][0]',           \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, None, 6)      228         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_3[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "8Cy5L0Fk9ovO",
        "outputId": "9c6e7f7a-52b1-4ef0-da1a-0d618b72758c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 8s 16ms/step - loss: 0.9453 - accuracy: 0.4941 - val_loss: 0.6979 - val_accuracy: 0.4970\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.7096 - accuracy: 0.4989 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6988 - accuracy: 0.5018 - val_loss: 0.7006 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6963 - accuracy: 0.4944 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6957 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6955 - accuracy: 0.4976 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6955 - accuracy: 0.4969 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6955 - accuracy: 0.4973 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6950 - accuracy: 0.5101 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6949 - accuracy: 0.5018 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6952 - accuracy: 0.5014 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6955 - accuracy: 0.4952 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6943 - accuracy: 0.5107 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6949 - accuracy: 0.5018 - val_loss: 0.6961 - val_accuracy: 0.4970\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.6954 - accuracy: 0.4979 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6953 - accuracy: 0.5010 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6952 - accuracy: 0.4988 - val_loss: 0.6948 - val_accuracy: 0.4970\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6950 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6945 - accuracy: 0.5107 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6956 - accuracy: 0.4957 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6946 - accuracy: 0.4982 - val_loss: 0.6969 - val_accuracy: 0.4970\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6953 - accuracy: 0.4960 - val_loss: 0.6956 - val_accuracy: 0.4970\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6956 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.6954 - accuracy: 0.4918 - val_loss: 0.6964 - val_accuracy: 0.5030\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.6953 - accuracy: 0.4969 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.5040 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6946 - accuracy: 0.4992 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6946 - accuracy: 0.5006 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6954 - accuracy: 0.4961 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.6952 - accuracy: 0.4923 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6950 - accuracy: 0.4997 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6946 - accuracy: 0.5099 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6948 - accuracy: 0.5045 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6950 - accuracy: 0.4951 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6949 - accuracy: 0.4943 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6955 - accuracy: 0.4922 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6951 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6956 - accuracy: 0.4892 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6952 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6943 - accuracy: 0.5063 - val_loss: 0.6955 - val_accuracy: 0.5030\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.6946 - accuracy: 0.5077 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6952 - accuracy: 0.5022 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6944 - accuracy: 0.5029 - val_loss: 0.6961 - val_accuracy: 0.4970\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6946 - accuracy: 0.4985 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6942 - accuracy: 0.5040 - val_loss: 0.6950 - val_accuracy: 0.4970\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.5073 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6943 - accuracy: 0.5074 - val_loss: 0.6940 - val_accuracy: 0.4950\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6940 - accuracy: 0.5121 - val_loss: 0.6944 - val_accuracy: 0.4820\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.6938 - accuracy: 0.5100 - val_loss: 0.6944 - val_accuracy: 0.5050\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6938 - val_accuracy: 0.5050\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5230\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6885 - accuracy: 0.5254 - val_loss: 0.6914 - val_accuracy: 0.5500\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6825 - accuracy: 0.5479 - val_loss: 0.6836 - val_accuracy: 0.5350\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6725 - accuracy: 0.5823 - val_loss: 0.6543 - val_accuracy: 0.6270\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6530 - accuracy: 0.6242 - val_loss: 0.6323 - val_accuracy: 0.6380\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6446 - accuracy: 0.6403 - val_loss: 0.6293 - val_accuracy: 0.6700\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6354 - accuracy: 0.6454 - val_loss: 0.6200 - val_accuracy: 0.6620\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.6286 - accuracy: 0.6554 - val_loss: 0.6106 - val_accuracy: 0.6750\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6233 - accuracy: 0.6615 - val_loss: 0.6031 - val_accuracy: 0.6850\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6124 - accuracy: 0.6706 - val_loss: 0.6021 - val_accuracy: 0.6890\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.6047 - accuracy: 0.6787 - val_loss: 0.5924 - val_accuracy: 0.6810\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5949 - accuracy: 0.6913 - val_loss: 0.5651 - val_accuracy: 0.7060\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.5750 - accuracy: 0.7141 - val_loss: 0.5650 - val_accuracy: 0.7090\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.5556 - accuracy: 0.7324 - val_loss: 0.5150 - val_accuracy: 0.7650\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5235 - accuracy: 0.7551 - val_loss: 0.5105 - val_accuracy: 0.7790\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4984 - accuracy: 0.7687 - val_loss: 0.4859 - val_accuracy: 0.7900\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4727 - accuracy: 0.7900 - val_loss: 0.4390 - val_accuracy: 0.8030\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4506 - accuracy: 0.7990 - val_loss: 0.4206 - val_accuracy: 0.8130\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4305 - accuracy: 0.8144 - val_loss: 0.4089 - val_accuracy: 0.8210\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.4142 - accuracy: 0.8222 - val_loss: 0.3929 - val_accuracy: 0.8150\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4121 - accuracy: 0.8253 - val_loss: 0.3839 - val_accuracy: 0.8230\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3996 - accuracy: 0.8341 - val_loss: 0.4053 - val_accuracy: 0.8000\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3926 - accuracy: 0.8292 - val_loss: 0.3993 - val_accuracy: 0.8220\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.3777 - val_accuracy: 0.8260\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3819 - accuracy: 0.8376 - val_loss: 0.3747 - val_accuracy: 0.8280\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3731 - accuracy: 0.8382 - val_loss: 0.3783 - val_accuracy: 0.8290\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3677 - accuracy: 0.8431 - val_loss: 0.3680 - val_accuracy: 0.8350\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3679 - accuracy: 0.8419 - val_loss: 0.3763 - val_accuracy: 0.8270\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3599 - accuracy: 0.8470 - val_loss: 0.4567 - val_accuracy: 0.8080\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 6s 21ms/step - loss: 0.3538 - accuracy: 0.8483 - val_loss: 0.3713 - val_accuracy: 0.8310\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3547 - accuracy: 0.8488 - val_loss: 0.3937 - val_accuracy: 0.8200\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3532 - accuracy: 0.8494 - val_loss: 0.3760 - val_accuracy: 0.8290\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3502 - accuracy: 0.8493 - val_loss: 0.3554 - val_accuracy: 0.8390\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3490 - accuracy: 0.8490 - val_loss: 0.3663 - val_accuracy: 0.8240\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3431 - accuracy: 0.8498 - val_loss: 0.3669 - val_accuracy: 0.8370\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3415 - accuracy: 0.8525 - val_loss: 0.3800 - val_accuracy: 0.8120\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3406 - accuracy: 0.8548 - val_loss: 0.3501 - val_accuracy: 0.8330\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3346 - accuracy: 0.8550 - val_loss: 0.3872 - val_accuracy: 0.8190\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3336 - accuracy: 0.8551 - val_loss: 0.3563 - val_accuracy: 0.8360\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3332 - accuracy: 0.8589 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3279 - accuracy: 0.8591 - val_loss: 0.3413 - val_accuracy: 0.8370\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3318 - accuracy: 0.8571 - val_loss: 0.3812 - val_accuracy: 0.8180\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3211 - accuracy: 0.8581 - val_loss: 0.3492 - val_accuracy: 0.8310\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3298 - accuracy: 0.8572 - val_loss: 0.3498 - val_accuracy: 0.8400\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3226 - accuracy: 0.8595 - val_loss: 0.3780 - val_accuracy: 0.8280\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3269 - accuracy: 0.8572 - val_loss: 0.3922 - val_accuracy: 0.8210\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3245 - accuracy: 0.8618 - val_loss: 0.4012 - val_accuracy: 0.8130\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3252 - accuracy: 0.8600 - val_loss: 0.3693 - val_accuracy: 0.8250\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3198 - accuracy: 0.8639 - val_loss: 0.3626 - val_accuracy: 0.8320\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3182 - accuracy: 0.8617 - val_loss: 0.3686 - val_accuracy: 0.8370\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3148 - accuracy: 0.8634 - val_loss: 0.3597 - val_accuracy: 0.8320\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3172 - accuracy: 0.8630 - val_loss: 0.3498 - val_accuracy: 0.8290\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3159 - accuracy: 0.8623 - val_loss: 0.4080 - val_accuracy: 0.8160\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3171 - accuracy: 0.8636 - val_loss: 0.3675 - val_accuracy: 0.8260\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3103 - accuracy: 0.8679 - val_loss: 0.3992 - val_accuracy: 0.8230\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3126 - accuracy: 0.8649 - val_loss: 0.3766 - val_accuracy: 0.8280\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3113 - accuracy: 0.8658 - val_loss: 0.4021 - val_accuracy: 0.8160\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3108 - accuracy: 0.8632 - val_loss: 0.3742 - val_accuracy: 0.8280\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3049 - accuracy: 0.8690 - val_loss: 0.3666 - val_accuracy: 0.8250\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3068 - accuracy: 0.8664 - val_loss: 0.3776 - val_accuracy: 0.8250\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3077 - accuracy: 0.8677 - val_loss: 0.3780 - val_accuracy: 0.8250\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3059 - accuracy: 0.8701 - val_loss: 0.3715 - val_accuracy: 0.8230\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3034 - accuracy: 0.8691 - val_loss: 0.4189 - val_accuracy: 0.8250\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3007 - accuracy: 0.8675 - val_loss: 0.3982 - val_accuracy: 0.8230\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3005 - accuracy: 0.8721 - val_loss: 0.3609 - val_accuracy: 0.8240\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3013 - accuracy: 0.8700 - val_loss: 0.3767 - val_accuracy: 0.8220\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3041 - accuracy: 0.8669 - val_loss: 0.4152 - val_accuracy: 0.8110\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.3000 - accuracy: 0.8697 - val_loss: 0.3860 - val_accuracy: 0.8220\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.3047 - accuracy: 0.8666 - val_loss: 0.3706 - val_accuracy: 0.8260\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.3002 - accuracy: 0.8681 - val_loss: 0.4153 - val_accuracy: 0.8210\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ]
    }
  ]
}