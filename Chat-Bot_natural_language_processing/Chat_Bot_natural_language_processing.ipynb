{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9FhJLI1drPgZhyRkV8czH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozj1/Machine_Learning_and_Data_Science_projects/blob/main/Chat-Bot_natural_language_processing/Chat_Bot_natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data\n",
        "\n",
        "We will be working with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "  http://arxiv.org/abs/1502.05698\n"
      ],
      "metadata": {
        "id": "J-JpZRKJ-Ae-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTkh-4-XRBet",
        "outputId": "1e634924-8e57-4a14-9524-eeb51069c5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0GRWATf2A7Z-",
        "outputId": "4e11bfc7-e740-4abe-dc43-742c6c83e0e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "W-7nlyz69oul"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "V1Mr5f2I9oun"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "sNplFO3P9ouo"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/Dataset/chatbot_dataset/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## understanding the dataset format, a short story, a question, and an answer Yes or No"
      ],
      "metadata": {
        "id": "CtJXt0elDjxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_data))\n",
        "print(type(train_data))\n",
        "print(len(test_data))\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBV7H4PED5aa",
        "outputId": "0a6634dc-f254-46f4-fffc-5f8b21c43d3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "1000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehi_BpS6EKmT",
        "outputId": "f91f1d5f-f5b0-4495-f620-83c67b94e7d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping to get the sentence\n",
        "print(' '.join(train_data[0][0]))\n",
        "print(' '.join(train_data[0][1]))\n",
        "#now what is the answer?\n",
        "print(train_data[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3awpdMHqENdr",
        "outputId": "2f69e6a8-9d59-46e9-e222-aaa7056a12f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary moved to the bathroom . Sandra journeyed to the bedroom .\n",
            "Is Sandra in the hallway ?\n",
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how many unique words we have in the entire dataset using set() and unite them using union()."
      ],
      "metadata": {
        "id": "raARcfFcE_nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()\n",
        "all_data = test_data + train_data\n",
        "\n",
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "\n",
        "#answer dataset only has two words, we add them\n",
        "vocab.add('no')\n",
        "vocab.add('yes')\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0bP9JaFP3B",
        "outputId": "7479e83a-d724-41ac-84f6-36e22cbad532"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences\n",
        "#we find the max size of a story\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "print(max_story_len)\n",
        "#we find the max size of a question in the dataset\n",
        "max_question_len = max([len(data[1]) for data in all_data])\n",
        "print(max_question_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtXL9fwgFlHJ",
        "outputId": "6aed9410-88e7-4002-8e5b-3421052aca3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We vectorize the data so it can be understood by Keras."
      ],
      "metadata": {
        "id": "NKztrBDXG7_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eTQ3PnHJRp",
        "outputId": "204dfb22-3adf-4886-8dc6-192c880ae0dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'milk': 1,\n",
              " 'john': 2,\n",
              " 'no': 3,\n",
              " 'is': 4,\n",
              " '?': 5,\n",
              " 'kitchen': 6,\n",
              " 'grabbed': 7,\n",
              " 'back': 8,\n",
              " 'daniel': 9,\n",
              " 'took': 10,\n",
              " 'picked': 11,\n",
              " 'to': 12,\n",
              " 'bathroom': 13,\n",
              " '.': 14,\n",
              " 'travelled': 15,\n",
              " 'sandra': 16,\n",
              " 'in': 17,\n",
              " 'went': 18,\n",
              " 'put': 19,\n",
              " 'moved': 20,\n",
              " 'yes': 21,\n",
              " 'garden': 22,\n",
              " 'dropped': 23,\n",
              " 'office': 24,\n",
              " 'mary': 25,\n",
              " 'football': 26,\n",
              " 'apple': 27,\n",
              " 'journeyed': 28,\n",
              " 'down': 29,\n",
              " 'there': 30,\n",
              " 'the': 31,\n",
              " 'bedroom': 32,\n",
              " 'discarded': 33,\n",
              " 'hallway': 34,\n",
              " 'got': 35,\n",
              " 'left': 36,\n",
              " 'up': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "# We make separate lists for story, query, and answer.\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "B39NQvOxHuDy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
        "\n",
        "print(len(train_story_text))\n",
        "print(len(train_story_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezWjYjFpH2gY",
        "outputId": "17350d29-9f9c-4a9d-d799-dd322ac9d389"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functionalize Vectorization"
      ],
      "metadata": {
        "id": "bScJEEHeIbnC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "id": "T5grEdyr9ou9"
      },
      "outputs": [],
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        #\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "id": "pCRYzkAr9ou-"
      },
      "outputs": [],
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "id": "iFPb4OhM9ou_"
      },
      "outputs": [],
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p8xQt2UB9ou_",
        "outputId": "d3e42a02-3080-4455-d69e-7d94ace52cb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 31, 32, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 31, 27, 14],\n",
              "       [ 0,  0,  0, ..., 31, 22, 14],\n",
              "       [ 0,  0,  0, ..., 27, 30, 14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "inputs_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6mH0IsXV9ovA",
        "outputId": "7501442a-6368-4019-cf63-880c5b82a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31,  6,  5],\n",
              "       [ 4,  2, 17, 31, 22,  5],\n",
              "       ...,\n",
              "       [ 4, 25, 17, 31, 32,  5],\n",
              "       [ 4, 16, 17, 31, 22,  5],\n",
              "       [ 4, 25, 17, 31, 22,  5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "queries_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "DhaDoUld9ovB",
        "outputId": "5ec10f9c-9eb8-4490-9bf3-a7e94425ecc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "answers_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "idSgpnbN9ovB",
        "outputId": "887a36f9-e03c-42b1-95ce-fbead1422742",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sum(answers_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Gi2_q80D9ovC",
        "outputId": "b92ecb97-f4bc-4eee-893f-41b326a7f9ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokenizer.word_index['yes']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vXD3zd239ovD",
        "outputId": "de8df310-ae09-49de-8c92-129d4c7ed50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tokenizer.word_index['no']"
      ]
    }
  ]
}